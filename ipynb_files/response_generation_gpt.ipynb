{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9036438d-ac07-432d-a382-c0e87eb95583",
   "metadata": {},
   "source": [
    "# Import Statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5180d8aa-0f60-4a96-86d8-fff664c8a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "<string>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "from emotion_inference import predict_emotion as _model_predict_emotion\n",
    "from dialogue_inference import predict_act as _model_predict_act\n",
    "from typing import List, Dict, Tuple\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00aed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your api key here.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Enter your Api key here\"\n",
    "os.environ.setdefault(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "# Initializing client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Selecting the model\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3dc1d",
   "metadata": {},
   "source": [
    "# Defining tone mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60cf4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTION_TONE = {\n",
    "    \"anger\":   \"calm, validating, non-confrontational\",\n",
    "    \"sadness\": \"warm, reassuring, supportive\",\n",
    "    \"disgust\":    \"patient, reflective, balanced\",\n",
    "    \"happiness\":     \"positive, concise, appreciative\",\n",
    "    \"fear\":    \"gentle, grounding, confidence-building\",\n",
    "    \"surprise\":\"curious, clarifying, steady\",\n",
    "    \"neutral\": \"matter-of-fact, clear\",\n",
    "}\n",
    "\n",
    "DIALOGUE_ACT_STYLE = {\n",
    "    \"question\": \"answer clearly, then ask one helpful follow-up if useful\",\n",
    "    \"inform\": \"be concise and structured. answer in one sentence\",\n",
    "    \"directive\": \"acknowledge and follow whats specified.\",\n",
    "    \"commisive\": \"confirm next steps, express encouragement, and offer assistance if needed.\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7cc2b6",
   "metadata": {},
   "source": [
    "# Plugging in pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3558673a-5367-4d79-a916-6af795ccb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting emotion from input text using pre-trained emotion classification model.\n",
    "def predict_emotion_from_model(text, history=None):\n",
    "    res = _model_predict_emotion(text)\n",
    "    label = (res.get(\"pred\") or \"\").strip().lower()\n",
    "    prob  = float(res.get(\"prob\", 0.0))\n",
    "    if label == \"no emotion\": label = \"neutral\"\n",
    "    if label not in {\"neutral\",\"anger\",\"disgust\",\"fear\",\"happiness\",\"sadness\",\"surprise\"}:\n",
    "        label = \"neutral\"\n",
    "    return label, prob\n",
    "\n",
    "# Predicting dialogue act from input text using pre-trained dialogue act classification model.\n",
    "def predict_act_from_model(text, history=None):\n",
    "    res = _model_predict_act(text)\n",
    "    label = (res.get(\"pred\") or \"INFORM\").upper()\n",
    "    prob = float(res.get(\"prob\", 0.0))\n",
    "    # Clamp to the set you use in the engine\n",
    "    if label not in {\"QUERY\",\"DIRECT\",\"COMMISSIVE\",\"INFORM\"}:\n",
    "        label = \"INFORM\"\n",
    "    return label, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26557472",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c196d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_history(history, max_turns=3):\n",
    "    return history[-max_turns:]\n",
    "\n",
    "def _bullet_history(history):\n",
    "    lines = []\n",
    "    for t in reversed(history):\n",
    "        who = \"User\" if t[\"role\"] == \"user\" else \"Assistant\"\n",
    "        lines.append(f\"- {who}: {t['text']}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Constructing message for gpt-4o-mini model.\n",
    "def build_messages(user_utt, history, emotion, e_prob, act, a_prob, conditioning=None):\n",
    "    cond = conditioning or {\"use_emotion\": True, \"use_act\": True}\n",
    "\n",
    "    # Fetching tone from detected emotion\n",
    "    tone = (\n",
    "        EMOTION_TONE.get(emotion, \"clear and respectful\")\n",
    "        if cond.get(\"use_emotion\", True)\n",
    "        else \"clear and respectful\"\n",
    "    )\n",
    "\n",
    "    # Fetching style from detected dialogue act\n",
    "    act_style = (\n",
    "        DIALOGUE_ACT_STYLE.get(act, \"neutral and professional\")\n",
    "        if cond.get(\"use_act\", True)\n",
    "        else \"neutral and professional\"\n",
    "    )\n",
    "\n",
    "    sys_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a concise, empathetic assistant.\\n\"\n",
    "            \"Goals: (1) Be correct and helpful.\"\n",
    "            \"(2) STRICTLY match the provided emotional tone when available. \"\n",
    "            \"(3) STRICTLY follow the provided dialogue-act style when available.\\n\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    body = [\n",
    "        \"[CONTEXT]\",\n",
    "        f'Latest user utterance: \"{user_utt}\"',\n",
    "        \"Dialogue history (most recent first):\",\n",
    "        _bullet_history(_select_history(history)),\n",
    "        \"\"\n",
    "    ]\n",
    "\n",
    "    # Adding emotion condition to prompt.\n",
    "    if cond.get(\"use_emotion\", True):\n",
    "        body.append(f\"Predicted emotion: {emotion} (p={e_prob:.2f})\")\n",
    "        body.append(f\"TONE TO USE (STRICT): {tone}\")\n",
    "    else:\n",
    "        body.append(\"Emotion conditioning: DISABLED\")\n",
    "        body.append(\"TONE TO USE (STRICT): clear and respectful\")\n",
    "\n",
    "    # Adding act condition to prompt.\n",
    "    if cond.get(\"use_act\", True):\n",
    "        body.append(f\"Predicted dialogue act: {act} (p={a_prob:.2f})\")\n",
    "        body.append(f\"STYLE TO USE (STRICT): {act_style}\")\n",
    "    else:\n",
    "        body.append(\"Dialogue-act conditioning: DISABLED\")\n",
    "        body.append(\"STYLE TO USE (STRICT): neutral and professional\")\n",
    "\n",
    "    body.append(\n",
    "        \"Combine tone + style: tone controls affect/wording; style controls structure/response pattern. \"\n",
    "        \"Do not override either when provided.\"\n",
    "    )\n",
    "    body.append(\"Never fabricate facts. If uncertain, ask one crisp clarifying question.\")\n",
    "\n",
    "    dev_msg = {\"role\": \"developer\", \"content\": \"\\n\".join(body)}\n",
    "    user_msg = {\"role\": \"user\", \"content\": user_utt}\n",
    "    return [sys_msg, dev_msg, user_msg]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb002e5-d700-4025-9aec-94fd68b24903",
   "metadata": {},
   "source": [
    "# API call to gpt-4o-mini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe67c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making request to gpt-4o-mini model.\n",
    "def llm_chat(messages, model=MODEL, temperature=0.6, max_tokens=300):\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        messages=messages\n",
    "    )\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463150b7",
   "metadata": {},
   "source": [
    "# Response Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641b95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to manages the complete conversation flow.\n",
    "class ResponseEngine:\n",
    "    def __init__(self, predict_emotion_fn, predict_act_fn, llm_chat_fn, max_history=6, conditioning=None):\n",
    "        self.predict_emotion_fn = predict_emotion_fn\n",
    "        self.predict_act_fn = predict_act_fn\n",
    "        self.llm_chat_fn = llm_chat_fn\n",
    "        self.history = []\n",
    "        self.max_history = max_history\n",
    "        self.cond = conditioning or {\"use_emotion\": True, \"use_act\": True}\n",
    "\n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "\n",
    "    def step(self, user_text, return_debug=False):\n",
    "        self.history.append({\"role\": \"user\", \"text\": user_text})\n",
    "        self.history = self.history[-self.max_history:]\n",
    "\n",
    "        emotion, e_prob = self.predict_emotion_fn(user_text, self.history)\n",
    "        act, a_prob = self.predict_act_fn(user_text, self.history)\n",
    "\n",
    "        messages = build_messages(user_text, self.history, emotion, e_prob, act, a_prob, self.cond)\n",
    "        assistant_text = self.llm_chat_fn(messages).strip()\n",
    "\n",
    "        self.history.append({\"role\": \"assistant\", \"text\": assistant_text})\n",
    "        self.history = self.history[-self.max_history:]\n",
    "\n",
    "        if return_debug:\n",
    "            return {\n",
    "                \"user\": user_text,    \n",
    "                \"reply\": assistant_text,\n",
    "                \"emotion\": (emotion, e_prob),\n",
    "                \"act\": (act, a_prob),\n",
    "                \"conditioning\": dict(self.cond)\n",
    "            }\n",
    "        return assistant_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "334c8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to produce sample outputs.\n",
    "def sample_demo(engine):\n",
    "    for utterance in [\n",
    "        \"How’s the weather today? Hopefully it’s not terrible again.\",\n",
    "        \"Please remind me to call Monica at 5 PM so I can share the good news.\",\n",
    "        \"Where is the nearest coffee shop?\",\n",
    "        \"I live near Central Perk in New York.\"\n",
    "        \n",
    "    ]:\n",
    "        out = engine.step(utterance, return_debug=True)\n",
    "        print(f\"User: {out['user']}\")\n",
    "        print(f\"Assistant: {out['reply']}\")\n",
    "        print(f\"(emotion={out['emotion'][0]} p={out['emotion'][1]:.2f} | act={out['act'][0]} p={out['act'][1]:.2f} | conditioning={out['conditioning']})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26888192-b5fb-4c94-946b-a2f0dbe136b8",
   "metadata": {},
   "source": [
    "# Ablation Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc656a-d981-490d-876f-bd55fc11b9be",
   "metadata": {},
   "source": [
    "## Response Generation with  both emotion and dialogue act conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852bdc7d-289d-4f7a-afab-a904e2a3d258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Generation with  both emotion and dialogue act conditioning.\n",
      "\n",
      "User: How’s the weather today? Hopefully it’s not terrible again.\n",
      "Assistant: Today’s weather is mild with some clouds, so it should be an improvement from recent days.\n",
      "(emotion=anger p=0.85 | act=inform p=0.65 | conditioning={'use_emotion': True, 'use_act': True})\n",
      "\n",
      "User: Please remind me to call Monica at 5 PM so I can share the good news.\n",
      "Assistant: Got it! I'll remind you to call Monica at 5 PM to share your good news. That's exciting!\n",
      "(emotion=happiness p=0.75 | act=directive p=0.74 | conditioning={'use_emotion': True, 'use_act': True})\n",
      "\n",
      "User: Where is the nearest coffee shop?\n",
      "Assistant: To help you find the nearest coffee shop, could you please provide your current location or the name of a nearby area?\n",
      "(emotion=neutral p=0.60 | act=question p=0.72 | conditioning={'use_emotion': True, 'use_act': True})\n",
      "\n",
      "User: I live near Central Perk in New York.\n",
      "Assistant: The nearest coffee shop to Central Perk is likely the Starbucks located at 1001 Avenue of the Americas.\n",
      "(emotion=neutral p=0.60 | act=inform p=0.65 | conditioning={'use_emotion': True, 'use_act': True})\n",
      "\n",
      "******************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"Response Generation with  both emotion and dialogue act conditioning.\")\n",
    "print()\n",
    "engine = ResponseEngine(\n",
    "predict_emotion_fn=predict_emotion_from_model,\n",
    "predict_act_fn=predict_act_from_model,\n",
    "llm_chat_fn=llm_chat,\n",
    "conditioning={\"use_emotion\": True, \"use_act\": True}\n",
    ")\n",
    "sample_demo(engine)\n",
    "print(\"*\"*150)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298415d-3548-46d8-be51-cacc4eac48ed",
   "metadata": {},
   "source": [
    "## Response Generation with emotion conditioning only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676130f1-5529-4781-ad88-01a3784d6205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Generation with emotion conditioning only\n",
      "\n",
      "User: How’s the weather today? Hopefully it’s not terrible again.\n",
      "Assistant: I understand your frustration with the weather. Today, it looks like there will be a mix of clouds and sun, with mild temperatures. Hopefully, it will be more pleasant for you.\n",
      "(emotion=anger p=0.85 | act=inform p=0.65 | conditioning={'use_emotion': True, 'use_act': False})\n",
      "\n",
      "User: Please remind me to call Monica at 5 PM so I can share the good news.\n",
      "Assistant: I can't set reminders, but you could use your phone or a reminder app to help with that! Sharing good news is always exciting—I'm sure Monica will be thrilled!\n",
      "(emotion=happiness p=0.75 | act=directive p=0.74 | conditioning={'use_emotion': True, 'use_act': False})\n",
      "\n",
      "User: Where is the nearest coffee shop?\n",
      "Assistant: To find the nearest coffee shop, you can use a map application on your phone or computer. Just enter \"coffee shop\" in the search bar, and it will show you the closest options along with directions.\n",
      "(emotion=neutral p=0.60 | act=question p=0.72 | conditioning={'use_emotion': True, 'use_act': False})\n",
      "\n",
      "User: I live near Central Perk in New York.\n",
      "Assistant: That's great! Central Perk is a popular spot. If you need any information or recommendations in that area, feel free to ask!\n",
      "(emotion=neutral p=0.60 | act=inform p=0.65 | conditioning={'use_emotion': True, 'use_act': False})\n",
      "\n",
      "******************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"Response Generation with emotion conditioning only\")\n",
    "print()\n",
    "engine = ResponseEngine(\n",
    "predict_emotion_fn=predict_emotion_from_model,\n",
    "predict_act_fn=predict_act_from_model,\n",
    "llm_chat_fn=llm_chat,\n",
    "conditioning={\"use_emotion\": True, \"use_act\": False}\n",
    ")\n",
    "sample_demo(engine)\n",
    "print(\"*\"*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae12622-6397-4f4f-9854-668d2cc2693e",
   "metadata": {},
   "source": [
    "## Response Generation with dialogue act conditioning only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b7c495-fd8b-4b79-be2b-7429db397531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Generation with dialogue act conditioning only\n",
      "\n",
      "User: How’s the weather today? Hopefully it’s not terrible again.\n",
      "Assistant: I cannot provide real-time weather updates, but you can check a reliable weather website or app for the latest conditions in your area.\n",
      "(emotion=anger p=0.85 | act=inform p=0.65 | conditioning={'use_emotion': False, 'use_act': True})\n",
      "\n",
      "User: Please remind me to call Monica at 5 PM so I can share the good news.\n",
      "Assistant: I can't set reminders, but you might want to set an alarm on your phone or use a reminder app for that.\n",
      "(emotion=happiness p=0.75 | act=directive p=0.74 | conditioning={'use_emotion': False, 'use_act': True})\n",
      "\n",
      "User: Where is the nearest coffee shop?\n",
      "Assistant: I don’t have access to your location, but you can easily find the nearest coffee shop using a maps app on your phone or by searching online. Would you like tips on how to use those apps?\n",
      "(emotion=neutral p=0.60 | act=question p=0.72 | conditioning={'use_emotion': False, 'use_act': True})\n",
      "\n",
      "User: I live near Central Perk in New York.\n",
      "Assistant: You can find the nearest coffee shop by using a maps app on your phone or searching online for coffee shops near Central Perk.\n",
      "(emotion=neutral p=0.60 | act=inform p=0.65 | conditioning={'use_emotion': False, 'use_act': True})\n",
      "\n",
      "******************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"Response Generation with dialogue act conditioning only\")\n",
    "print()\n",
    "engine = ResponseEngine(\n",
    "predict_emotion_fn=predict_emotion_from_model,\n",
    "predict_act_fn=predict_act_from_model,\n",
    "llm_chat_fn=llm_chat,\n",
    "conditioning={\"use_emotion\": False, \"use_act\": True}\n",
    ")\n",
    "sample_demo(engine)\n",
    "print(\"*\"*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39670c7f-8dab-4173-b9e4-09fe172c14df",
   "metadata": {},
   "source": [
    "## Response Generation without Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7ec409-5356-4284-a122-fb78af243374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Generation without Conditioning\n",
      "\n",
      "User: How’s the weather today? Hopefully it’s not terrible again.\n",
      "Assistant: I currently don't have real-time weather information. I recommend checking a reliable weather website or app for the most accurate update. If you’d like, I can help you with general tips on how to prepare for different weather conditions.\n",
      "(emotion=anger p=0.85 | act=inform p=0.65 | conditioning={'use_emotion': False, 'use_act': False})\n",
      "\n",
      "User: Please remind me to call Monica at 5 PM so I can share the good news.\n",
      "Assistant: I can't set reminders, but you might consider using a reminder app or setting an alarm on your phone for 5 PM to call Monica.\n",
      "(emotion=happiness p=0.75 | act=directive p=0.74 | conditioning={'use_emotion': False, 'use_act': False})\n",
      "\n",
      "User: Where is the nearest coffee shop?\n",
      "Assistant: I don't have access to real-time location data. However, you can use a map application on your phone or computer to find the nearest coffee shop. Would you like tips on how to search effectively?\n",
      "(emotion=neutral p=0.60 | act=question p=0.72 | conditioning={'use_emotion': False, 'use_act': False})\n",
      "\n",
      "User: I live near Central Perk in New York.\n",
      "Assistant: That's great! Central Perk is a popular spot. If you're looking for coffee shops nearby, you might want to check local listings or map applications for the most convenient options. Would you like any specific recommendations or tips?\n",
      "(emotion=neutral p=0.60 | act=inform p=0.65 | conditioning={'use_emotion': False, 'use_act': False})\n",
      "\n",
      "******************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"Response Generation without Conditioning\")\n",
    "print()\n",
    "engine = ResponseEngine(\n",
    "predict_emotion_fn=predict_emotion_from_model,\n",
    "predict_act_fn=predict_act_from_model,\n",
    "llm_chat_fn=llm_chat,\n",
    "conditioning={\"use_emotion\": False, \"use_act\": False}\n",
    ")\n",
    "sample_demo(engine)\n",
    "print(\"*\"*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fdc6e2-1029-4690-9dab-75c360da436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_project)",
   "language": "python",
   "name": "nlp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
