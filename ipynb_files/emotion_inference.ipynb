{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8646a3-76cc-4f3e-8c6b-220dec3ed264",
   "metadata": {},
   "source": [
    "# Import Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8bd959-92d7-4816-801b-49e29abf4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f8f367-e693-44bf-9d4b-af56e52712fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading saved model and vocab path.\n",
    "STATE_PATH = \"../models/checkpoints/emotion_classifier/tuning/emotion_classifier_last.pt\"\n",
    "VOCAB_PATH = \"../data/processed/vocab.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a178c01-257f-4d70-9d1d-6748b4ce1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from numeric emotion IDs to their corresponding emotion labels\n",
    "id2label = {\n",
    "    0: \"no emotion\",\n",
    "    1: \"anger\",\n",
    "    2: \"disgust\",\n",
    "    3: \"fear\",\n",
    "    4: \"happiness\",\n",
    "    5: \"sadness\",\n",
    "    6: \"surprise\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c2db5-47d6-45fc-8880-f9dcd3b4148f",
   "metadata": {},
   "source": [
    "# BiLSTM based emotion classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ddd1e1-8480-4dc8-8109-21bc913b1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A BiLSTM-based emotion classification model.\n",
    "class BiLSTMEmotionClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        avg_pool = torch.mean(lstm_out, dim=1)\n",
    "        dropped = self.dropout(avg_pool)\n",
    "        output = self.fc(dropped)\n",
    "        return self.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8015740-5354-48ad-8344-41bbb8ec79d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_60456\\4131369532.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(STATE_PATH, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTMEmotionClassifier(\n",
       "  (embedding): Embedding(10948, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=7, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the vocabulary from file\n",
    "with open(VOCAB_PATH, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "PAD_IDX = vocab[\"<PAD>\"]\n",
    "UNK_IDX = vocab[\"<UNK>\"]\n",
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "# Model hyperparameters\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 64\n",
    "OUTPUT_DIM = 7\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the BiLSTM-based emotion classifier\n",
    "model = BiLSTMEmotionClassifier(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    pad_idx=PAD_IDX\n",
    ").to(device)\n",
    "\n",
    "# Load the pre-trained model weights\n",
    "state = torch.load(STATE_PATH, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c62f52-1e15-4726-a02b-ee3187ae7e04",
   "metadata": {},
   "source": [
    "### Pre-processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b9103a-ef94-4d6d-8844-b7a267dd7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess a text string into a list of tokens.\n",
    "def preprocess_text(s):\n",
    "    try:\n",
    "        import nltk\n",
    "        from nltk.corpus import stopwords\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        from nltk import word_tokenize\n",
    "        try:\n",
    "            nltk.download('punkt', quiet=True)\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "            nltk.download('wordnet', quiet=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        s = s.lower()\n",
    "        s = re.sub(r\"http\\S+\", \"\", s)\n",
    "        s = re.sub(r\"[^a-zA-Z\\s]\", \" \", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        toks = word_tokenize(s)\n",
    "        return [lemmatizer.lemmatize(t) for t in toks if t and t not in stop_words]\n",
    "    except Exception:\n",
    "        s = s.lower()\n",
    "        s = re.sub(r\"http\\S+\", \"\", s)\n",
    "        s = re.sub(r\"[^a-zA-Z\\s]\", \" \", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        return [t for t in s.split(\" \") if t]\n",
    "\n",
    "# Function to split a text string into sentences.\n",
    "def sent_split(s):\n",
    "    try:\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        return [x.strip() for x in sent_tokenize(s) if x.strip()]\n",
    "    except Exception:\n",
    "        parts = re.split(r'(?<=[.!?])\\s+', s.strip())\n",
    "        return [x for x in parts if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426e9d41-8e3f-4235-b159-0daa4d3037af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sequence length for model input\n",
    "MAX_LEN = 50\n",
    "\n",
    "# Function to convert a list of tokens into a fixed-length tensor of token IDs.\n",
    "def encode(tokens):\n",
    "    ids = [vocab.get(t, UNK_IDX) for t in tokens[:MAX_LEN]]\n",
    "    ids += [PAD_IDX] * (MAX_LEN - len(ids))\n",
    "    return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "# Function to split a list of tokens into fixed-size chunks.\n",
    "def chunks(tokens, size=MAX_LEN):\n",
    "    return [tokens[i:i+size] for i in range(0, len(tokens), size)] or [[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd96c1b-f25e-45e1-9c2b-8ada4b680f68",
   "metadata": {},
   "source": [
    "### Predicting emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450d6f73-b733-4e78-bc5d-13b08d1f0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the emotion of a given text input using the BiLSTMEmotionClassifier.\n",
    "@torch.no_grad()\n",
    "def predict_emotion(text, agg=\"mean\", return_breakdown=True):\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return {\"input\": text, \"pred\": None, \"prob\": 0.0, \"note\": \"Empty input\"}\n",
    "\n",
    "    sentences = sent_split(text)\n",
    "    if not sentences:\n",
    "        return {\"input\": text, \"pred\": None, \"prob\": 0.0, \"note\": \"No sentences found\"}\n",
    "\n",
    "    per_sentence = []\n",
    "    probs_matrix = []\n",
    "\n",
    "    for s in sentences:\n",
    "        tokens = preprocess_text(s)\n",
    "        if not tokens:\n",
    "            continue\n",
    "\n",
    "        chs = chunks(tokens, MAX_LEN)\n",
    "        batch = torch.stack([encode(c) for c in chs], dim=0).to(device)\n",
    "\n",
    "        logp = model(batch)\n",
    "        p = logp.exp()\n",
    "\n",
    "        if agg == \"max\":\n",
    "            p_sent = p.max(dim=0).values\n",
    "        else:\n",
    "            p_sent = p.mean(dim=0)\n",
    "\n",
    "        probs_matrix.append(p_sent.cpu().numpy())\n",
    "\n",
    "        if return_breakdown and len(sentences) > 1:\n",
    "            pred_idx = int(p_sent.argmax().item())\n",
    "            per_sentence.append({\n",
    "                \"text\": s,\n",
    "                \"pred\": id2label[pred_idx],\n",
    "                \"prob\": round(float(p_sent[pred_idx].item()), 2)\n",
    "            })\n",
    "\n",
    "    if not probs_matrix:\n",
    "        return {\"input\": text, \"pred\": None, \"prob\": 0.0, \"note\": \"No valid tokens after preprocessing\"}\n",
    "\n",
    "    P = np.stack(probs_matrix, axis=0)\n",
    "    P_agg = P.max(axis=0) if agg == \"max\" else P.mean(axis=0)\n",
    "    final_idx = int(P_agg.argmax())\n",
    "    final_prob = float(P_agg[final_idx])\n",
    "\n",
    "    out = {\n",
    "        \"input\": text,\n",
    "        \"pred_id\": final_idx,\n",
    "        \"pred\": id2label[final_idx],\n",
    "        \"prob\": round(final_prob, 2),\n",
    "        \"num_sentences\": len(sentences),\n",
    "        \"agg\": agg\n",
    "    }\n",
    "    if return_breakdown and per_sentence:\n",
    "        out[\"per_sentence\"] = per_sentence\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_project)",
   "language": "python",
   "name": "nlp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
